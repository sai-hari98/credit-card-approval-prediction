# Clear the workspace
rm(list=ls())
cat("\014")
# Use menu /Session/Set Working Directory/Choose Directory Or command below to set working directory
setwd("/Users/ShujingSun/Desktop/Teaching/")

# Classification Tree with rpart, utilities from caret, rpart.plot for plotting the tree
library(rpart)
#install.packages("caret")
library(caret)
library(rpart.plot)

# load the cellco dataset with 1K observations
load('cellco1K.Rda')

# split the data into training and test data sets
set.seed(123)   # for reproducible results
train <- sample(1:nrow(cellco), (2/3)*nrow(cellco))
cellco.train <- cellco[train,]
cellco.test <- cellco[-train,]

#let us take a look at the distribution of the class variable in the training data set
prop.table(table(cellco.train$churn))  #neg 52%, pos 48%


######### (1) Grow the Biggest Tree ######### 
# smaller minsplit and cp result in larger trees
# xval = 10: 10 folds cross-validation to determine error rate 
# minsplit = 2: min number of observations to attempt split
# cp = 0: minimum improvement in complexity parameter for splitting
fit.big <- rpart(churn ~ ., 
            data=cellco.train,
            control=rpart.control(xval=10, minsplit=2, cp=0))

# object fit.big$frame has a row for each node in the tree
nrow(fit.big$frame) # 247 nodes

# extract the vector of predicted values for churn for every row
churn.pred <- predict(fit.big, cellco.train, type="class")
# extract the actual value of churn for every row
churn.actual <- cellco.train$churn
# confusion matrix for training data cellco.train 
confusionMatrix(table(churn.pred,churn.actual), positive='pos')

# confusion matrix for hold out data in cellco.test
churn.pred <- predict(fit.big, cellco.test, type="class")
churn.actual <- cellco.test$churn
confusionMatrix(table(churn.pred,churn.actual), positive='pos')


######### (2) PRE-PRUNING using "minsplit" ######### 
fit.small <- rpart(churn ~ ., 
                  data=cellco.train,
                  control=rpart.control(xval=10, minsplit=50, cp=0))
nrow(fit.small$frame) # 23 nodes

# compute the confusion matrix and accuracy
# training data
confusionMatrix(table(pred=predict(fit.small, cellco.train, type="class"),
                      actual=cellco.train$churn), positive='pos')

# testing data
confusionMatrix(table(pred=predict(fit.small, cellco.test, type="class"),
                      actual=cellco.test$churn), positive='pos')


######### (3) POST-PRUNING the big tree with "prune.rpart" & "Complexity Parameter" ######### 
# Examine the trade off between complexity and error rate
#find the CP which provides the lowest error
#which min fn gives index with low value
bestcp <- fit.big$cptable[which.min(fit.big$cptable[,"xerror"]),"CP"]
bestcp   

# The lowest error occurs at CP = bestcp
# We can use this for post-pruning
fit.post <- prune.rpart(fit.big, cp=bestcp)
nrow(fit.post$frame)  

# plot the tree - NOTE. same as pre-pruned tree fit.small2 
prp(fit.post, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, 
    main="Post-prune Tree with best cp")  

# compute the confusion matrices and accuracy 
confusionMatrix(table(predict(fit.post, cellco.train, type="class"),
                      cellco.train$churn), positive='pos')

confusionMatrix(table(predict(fit.post, cellco.test, type="class"),
                      cellco.test$churn), positive='pos')


